services:
  airflow-pipeline:
    container_name: airflow-pipeline
    build: ./airflow-pipeline
    volumes:
      - ./airflow-pipeline/dags:/opt/airflow/dags
      - ./airflow-pipeline/plugins:/opt/airflow/plugins
      - ./airflow-pipeline/config:/opt/airflow/config
      - ./airflow-pipeline/logs:/opt/airflow/logs
    ports:
      - 8080:8080
    env_file:
      - .env.prod
    restart: always
  
  server:
    container_name: server
    build: ./server
    volumes:
      - ./server:/server
    ports:
      - 5000:5000
    environment:
      - FLASK_ENV=production
    env_file:
      - .env.prod
    depends_on:
      airflow-pipeline:
        condition: service_started
    restart: always

  worker:
    container_name: worker
    build: ./server
    command: celery -A app.celery worker --loglevel=info -Q summarize_queue,send_news_queue,synthesize_news_queue
    volumes:
      - ./server:/server
    environment:
      - FLASK_ENV=production
      - PYTHONUNBUFFERED=1
    env_file:
      - .env.prod
    # depends_on:
    #   server:
    #     condition: service_started
    extra_hosts: 
    - "host.docker.internal:host-gateway"
    restart: always

  server-slave:
    container_name: server-slave
    build: ./server-slave
    volumes:
      - ./server-slave:/server-slave
    ports:
      - 7000:7000
    restart: always

  beat:
    container_name: beat
    build: ./server
    command: celery -A app.celery beat --loglevel=info
    volumes:
      - ./server:/server
    environment:
      - FLASK_ENV=production
    env_file:
      - .env.prod
    # depends_on:
    #   server:
    #     condition: service_started
  